import React, { useState, useRef, useEffect, useCallback } from 'react';
import { useNavigate } from 'react-router-dom';
import { toast } from 'react-toastify';
import { X, PlayCircle, StopCircle, RotateCcw, Trophy, Target, Clock } from 'lucide-react';
import { motion } from 'framer-motion';
import { useTheme } from '../utils/ThemeContext';
import { GESTURE_DATABASE } from '../utils/gestureDatabase';

// MediaPipe imports
import { Hands } from '@mediapipe/hands';
import { Camera } from '@mediapipe/camera_utils';
import { drawConnectors, drawLandmarks } from '@mediapipe/drawing_utils';

// Socket.IO import
import io from 'socket.io-client';

// Create gesture options from database
const GESTURE_OPTIONS = Object.keys(GESTURE_DATABASE).map(key => ({
  value: key,
  label: GESTURE_DATABASE[key].description,
  data: GESTURE_DATABASE[key]
}));

const GesturePracticeMLPage = () => {
  const navigate = useNavigate();
  const { theme } = useTheme();
  const [selectedGesture, setSelectedGesture] = useState('');
  const [isPracticing, setIsPracticing] = useState(false);
  const [stats, setStats] = useState({ correct: 0, wrong: 0, total: 0, accuracy: 0 });
  const [currentStatus, setCurrentStatus] = useState('Select a gesture to begin');
  const [socket, setSocket] = useState(null);
  const [isConnected, setIsConnected] = useState(false);

  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const streamRef = useRef(null);
  const animationFrameRef = useRef(null);

  // Initialize camera and MediaPipe
  useEffect(() => {
    const initCamera = async () => {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { width: 640, height: 480, facingMode: 'user' }
        });
        streamRef.current = stream;
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
          videoRef.current.style.transform = 'scaleX(-1)'; // Flip horizontally to fix mirroring
        }

        // Initialize MediaPipe Hands
        const hands = new Hands({
          locateFile: (file) => {
            return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
          }
        });

        hands.setOptions({
          maxNumHands: 1,
          modelComplexity: 1,
          minDetectionConfidence: 0.5,
          minTrackingConfidence: 0.5
        });

        hands.onResults((results) => {
          if (canvasRef.current && results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
            const canvas = canvasRef.current;
            const ctx = canvas.getContext('2d');

            // Clear canvas
            ctx.clearRect(0, 0, canvas.width, canvas.height);

            // Draw hand landmarks
            drawConnectors(ctx, results.multiHandLandmarks[0], Hands.HAND_CONNECTIONS, {
              color: '#00FF00',
              lineWidth: 2
            });
            drawLandmarks(ctx, results.multiHandLandmarks[0], {
              color: '#FF0000',
              lineWidth: 1,
              radius: 3
            });

            // Send frame to server if practicing
            if (isPracticing && socket && isConnected) {
              sendFrameToServer();
            }
          }
        });

        // Initialize camera with MediaPipe
        const camera = new Camera(videoRef.current, {
          onFrame: async () => {
            if (videoRef.current) {
              await hands.send({ image: videoRef.current });
            }
          },
          width: 640,
          height: 480
        });

        camera.start();

      } catch (error) {
        console.error('Camera/MediaPipe initialization failed:', error);
        toast.error('Failed to initialize camera and hand tracking');
      }
    };

    initCamera();

    return () => {
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
    };
  }, []);

  // Initialize Socket.IO connection
  useEffect(() => {
    const socketConnection = io('http://localhost:5000');
    setSocket(socketConnection);

    socketConnection.on('connect', () => {
      console.log('Connected to server');
      setIsConnected(true);
      setCurrentStatus('Connected to server - Select a gesture to begin');
    });

    socketConnection.on('disconnect', () => {
      console.log('Disconnected from server');
      setIsConnected(false);
      setCurrentStatus('Disconnected from server');
      setIsPracticing(false);
    });

    socketConnection.on('practice-started', (data) => {
      console.log('Practice started:', data);
      setCurrentStatus('Practice session started - Close left fist to begin recording');
    });

    socketConnection.on('gesture-result', (result) => {
      console.log('Gesture result:', result);
      
      if (result.type === 'status_update') {
        setCurrentStatus(result.status);
      } else if (result.type === 'gesture_result') {
        setStats(result.stats);
        if (result.success) {
          setCurrentStatus(`✅ ${result.message}`);
          toast.success(result.message);
        } else {
          setCurrentStatus(`❌ ${result.message}`);
          toast.error(result.message);
        }
      }
    });

    socketConnection.on('practice-ended', () => {
      console.log('Practice ended');
      setIsPracticing(false);
      setCurrentStatus('Practice session ended');
    });

    socketConnection.on('practice-stopped', () => {
      console.log('Practice stopped');
      setIsPracticing(false);
      setCurrentStatus('Practice session stopped');
    });

    return () => {
      socketConnection.disconnect();
    };
  }, []);

  // Start Python process
  const startPractice = useCallback(async () => {
    if (!selectedGesture) {
      toast.error('Please select a gesture first');
      return;
    }

    try {
      setIsPracticing(true);
      setCurrentStatus('Connecting to ML processor...');

      // Start Python process via backend API
      const response = await fetch('http://localhost:5000/api/gestures/practice/start', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${localStorage.getItem('token')}`
        },
        body: JSON.stringify({ gesture: selectedGesture, cameraIndex: 0 })
      });

      if (!response.ok) {
        throw new Error('Failed to start practice session');
      }

      const data = await response.json();
      setIsConnected(true);
      setCurrentStatus('Ready! Close left fist to start recording');
      toast.success('ML Practice session started!');

      // Start capturing frames
      startFrameCapture();

    } catch (error) {
      console.error('Failed to start practice:', error);
      setIsPracticing(false);
      toast.error('Failed to start ML practice session');
    }
  }, [selectedGesture]);

  // Stop practice
  const stopPractice = useCallback(async () => {
    try {
      // Stop Python process via backend
      await fetch('http://localhost:5000/api/gestures/practice/stop', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${localStorage.getItem('token')}`
        }
      });

      setIsPracticing(false);
      setIsConnected(false);
      setCurrentStatus('Practice stopped');
      toast.info('Practice session ended');

      // Stop frame capture
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }

    } catch (error) {
      console.error('Failed to stop practice:', error);
    }
  }, []);

  // Capture and send frames to Python
  const startFrameCapture = useCallback(() => {
    const captureFrame = () => {
      if (!videoRef.current || !canvasRef.current || !isPracticing) return;

      const canvas = canvasRef.current;
      const ctx = canvas.getContext('2d');
      const video = videoRef.current;

      // Draw video frame to canvas
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      // Convert to base64 and send to backend
      const frameData = canvas.toDataURL('image/jpeg', 0.8);

      // Send frame to Python process via WebSocket or HTTP
      // For now, we'll use a simple approach - this would need WebSocket implementation
      // sendFrameToPython(frameData);

      animationFrameRef.current = requestAnimationFrame(captureFrame);
    };

    captureFrame();
  }, [isPracticing]);

  // Reset stats
  const resetStats = useCallback(() => {
    setStats({ correct: 0, wrong: 0, total: 0, accuracy: 0 });
    setCurrentStatus('Stats reset');
  }, []);

  // Handle gesture selection
  const handleGestureSelect = (gesture) => {
    setSelectedGesture(gesture);
    setCurrentStatus(`Selected: ${gesture.replace('_', ' ').toUpperCase()}`);
  };

  // Send frame to server
  const sendFrameToServer = useCallback(() => {
    if (!videoRef.current || !socket || !isConnected) return;

    try {
      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');
      canvas.width = 640;
      canvas.height = 480;
      
      // Draw the current video frame to canvas
      ctx.drawImage(videoRef.current, 0, 0, canvas.width, canvas.height);
      
      // Convert to base64
      const frameData = canvas.toDataURL('image/jpeg', 0.8);
      
      // Send to server
      socket.emit('frame', { frameData });
    } catch (error) {
      console.error('Error sending frame:', error);
    }
  }, [socket, isConnected]);

  // Start practice session
  const startPractice = () => {
    if (!selectedGesture) {
      toast.error('Please select a gesture first');
      return;
    }
    
    if (!socket || !isConnected) {
      toast.error('Not connected to server');
      return;
    }

    setIsPracticing(true);
    setCurrentStatus('Starting practice session...');
    
    socket.emit('start-practice', { gestureName: selectedGesture });
  };

  // Stop practice session
  const stopPractice = () => {
    if (socket && isConnected) {
      socket.emit('stop-practice');
    }
    setIsPracticing(false);
    setCurrentStatus('Practice stopped');
  };

  // Reset stats
  const resetStats = useCallback(() => {
    setStats({ correct: 0, wrong: 0, total: 0, accuracy: 0 });
    setCurrentStatus('Stats reset - Select a gesture to begin');
  }, []);

  return (
    <motion.div
      initial={{ opacity: 0, y: 20 }}
      animate={{ opacity: 1, y: 0 }}
      exit={{ opacity: 0, y: -20 }}
      className="min-h-screen bg-gradient-to-br from-gray-900 via-gray-800 to-gray-900 p-6"
    >
      <div className="max-w-7xl mx-auto">
        {/* Header */}
        <div className="flex items-center justify-between mb-8">
          <div>
            <h1 className="text-3xl font-bold text-white mb-2">ML Gesture Practice</h1>
            <p className="text-gray-400">Practice gestures with AI-powered recognition</p>
          </div>
          <button
            onClick={() => navigate('/gestures')}
            className="px-4 py-2 bg-gray-700 hover:bg-gray-600 text-white rounded-lg transition-colors"
          >
            <X className="w-5 h-5 inline mr-2" />
            Back to Gestures
          </button>
        </div>

        <div className="grid grid-cols-1 lg:grid-cols-3 gap-6">
          {/* Camera Section */}
          <div className="lg:col-span-2">
            <div className="bg-gray-800/50 backdrop-blur-lg rounded-2xl border border-gray-700 p-6">
              <h2 className="text-xl font-semibold text-white mb-4">Camera Feed</h2>

              <div className="relative aspect-video bg-black rounded-lg overflow-hidden mb-4">
                <video
                  ref={videoRef}
                  autoPlay
                  playsInline
                  muted
                  className="w-full h-full object-cover"
                />
                <canvas
                  ref={canvasRef}
                  width={640}
                  height={480}
                  className="absolute inset-0 w-full h-full"
                  style={{ display: 'none' }}
                />

                {/* Status Overlay */}
                <div className="absolute bottom-4 left-4 right-4">
                  <div className={`px-4 py-2 rounded-lg text-center ${
                    isConnected
                      ? 'bg-green-600 text-white'
                      : 'bg-yellow-600 text-white'
                  }`}>
                    {currentStatus}
                  </div>
                </div>
              </div>

              {/* Controls */}
              <div className="flex gap-4">
                <button
                  onClick={startPractice}
                  disabled={isPracticing || !selectedGesture}
                  className={`flex-1 px-6 py-3 rounded-lg font-semibold transition-all ${
                    isPracticing || !selectedGesture
                      ? 'bg-gray-600 text-gray-400 cursor-not-allowed'
                      : 'bg-green-600 hover:bg-green-500 text-white'
                  }`}
                >
                  <PlayCircle className="w-5 h-5 inline mr-2" />
                  Start Practice
                </button>

                <button
                  onClick={stopPractice}
                  disabled={!isPracticing}
                  className={`flex-1 px-6 py-3 rounded-lg font-semibold transition-all ${
                    !isPracticing
                      ? 'bg-gray-600 text-gray-400 cursor-not-allowed'
                      : 'bg-red-600 hover:bg-red-500 text-white'
                  }`}
                >
                  <StopCircle className="w-5 h-5 inline mr-2" />
                  Stop Practice
                </button>

                <button
                  onClick={resetStats}
                  className="px-6 py-3 bg-blue-600 hover:bg-blue-500 text-white rounded-lg font-semibold transition-all"
                >
                  <RotateCcw className="w-5 h-5 inline mr-2" />
                  Reset
                </button>
              </div>
            </div>
          </div>

          {/* Sidebar */}
          <div className="space-y-6">
            {/* Stats Card */}
            <div className="bg-gray-800/50 backdrop-blur-lg rounded-2xl border border-gray-700 p-6">
              <h3 className="text-lg font-semibold text-white mb-4 flex items-center">
                <Trophy className="w-5 h-5 mr-2 text-yellow-500" />
                Performance Stats
              </h3>

              <div className="space-y-3">
                <div className="flex justify-between items-center">
                  <span className="text-gray-400">Correct:</span>
                  <span className="text-green-400 font-semibold">{stats.correct}</span>
                </div>
                <div className="flex justify-between items-center">
                  <span className="text-gray-400">Wrong:</span>
                  <span className="text-red-400 font-semibold">{stats.wrong}</span>
                </div>
                <div className="flex justify-between items-center">
                  <span className="text-gray-400">Total:</span>
                  <span className="text-white font-semibold">{stats.total}</span>
                </div>
                <div className="flex justify-between items-center pt-2 border-t border-gray-700">
                  <span className="text-gray-400">Accuracy:</span>
                  <span className="text-cyan-400 font-bold">{stats.accuracy}%</span>
                </div>
              </div>
            </div>

            {/* Gesture Selection */}
            <div className="bg-gray-800/50 backdrop-blur-lg rounded-2xl border border-gray-700 p-6">
              <h3 className="text-lg font-semibold text-white mb-4 flex items-center">
                <Target className="w-5 h-5 mr-2 text-blue-500" />
                Select Gesture
              </h3>

              <div className="space-y-2 max-h-96 overflow-y-auto">
                {GESTURE_OPTIONS.map((option) => (
                  <button
                    key={option.value}
                    onClick={() => handleGestureSelect(option.value)}
                    disabled={isPracticing}
                    className={`w-full text-left p-3 rounded-lg transition-all ${
                      selectedGesture === option.value
                        ? 'bg-cyan-600 text-white'
                        : 'bg-gray-700 hover:bg-gray-600 text-gray-300 hover:text-white'
                    } ${isPracticing ? 'opacity-50 cursor-not-allowed' : ''}`}
                  >
                    <div className="font-medium">
                      {option.label}
                    </div>
                    <div className="text-sm opacity-75 mt-1">
                      {option.data.description}
                    </div>
                  </button>
                ))}
              </div>
            </div>

            {/* Instructions */}
            <div className="bg-gray-800/50 backdrop-blur-lg rounded-2xl border border-gray-700 p-6">
              <h3 className="text-lg font-semibold text-white mb-4 flex items-center">
                <Clock className="w-5 h-5 mr-2 text-purple-500" />
                Instructions
              </h3>

              <div className="text-sm text-gray-300 space-y-2">
                <p>1. Select a gesture from the list above</p>
                <p>2. Click "Start Practice" to begin</p>
                <p>3. Close left fist to start recording</p>
                <p>4. Perform the gesture as described</p>
                <p>5. Open left fist to finish attempt</p>
                <p>6. Get real-time feedback from AI</p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </motion.div>
  );
};

export default GesturePracticeMLPage;